ğŸ“Œ Flipkart Web Scraper Using Selenium + BeautifulSoup
This project is a Flipkart Web Scraper built using Python, Selenium, and BeautifulSoup, designed to extract product details such as Product Name, Price, Ratings, and Reviews and store them in a CSV file for further analysis. The scraper navigates through multiple pages and handles dynamic content loading effectively.

ğŸš€ Project Overview
The main goal of this project is to automate the process of extracting product data from Flipkart for data analysis or price tracking. The script leverages Selenium for web automation and BeautifulSoup for web parsing, while Pandas is used for data handling and storing the extracted data in a structured CSV format.

ğŸ› ï¸ Technology Stack
The project is built with Python as the core programming language. Selenium is used to handle web page automation, BeautifulSoup for parsing the HTML content, and Pandas for managing the data and saving it in CSV format. Additionally, ChromeDriver is required to interact with the Chrome browser.

ğŸ“‚ Project Structure
The project folder consists of the main script flipkart_scraper.py, a requirements.txt file to install the dependencies, an output.csv file where the scraped data will be saved, and a README.md file for documentation. A folder named assets is also included to store any screenshots or demo images of the output.

To run this project, first install the required libraries by running the command:
//pip install selenium beautifulsoup4 pandas
Next, download the ChromeDriver that matches your Chrome browser version and place it in the project folder. Then, simply run the script using:
//python flipkart_scraper.py

âœ… Features
Extract Product Names
Fetch Product Prices
Capture Ratings and Reviews
Navigate through multiple pages
Store data in CSV format
![Screenshot (48)](https://github.com/user-attachments/assets/6ac9245b-2c14-4fcc-bbb0-5bd7f242714e)

ğŸ¯ Execution Flow
1ï¸âƒ£ Open Flipkart website
2ï¸âƒ£ Search for the desired product
3ï¸âƒ£ Extract product details
4ï¸âƒ£ Navigate through multiple pages
5ï¸âƒ£ Store the data in CSV


